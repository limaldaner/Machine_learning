###########################################################################
#         HSV for crack and spalls feature extraction algorithm
#
# Canada
# August 2019
#
# Oriented by: Dr. M. Shahbazi
# Author: LiÃ©ge Maldaner
# E-mail: liege.malda@gmail.com
#
# Results:
###########################################################################

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage import data, color
import pandas as pd
import cv2
import scipy
#from scipy.misc import imread
import _pickle as pickle
import random
import os
from sklearn import svm
import csv
from os import listdir
from os.path import isfile, join
from openpyxl import load_workbook
from sklearn.decomposition import PCA


def compute_hsv_cell(hsv_image):
    """
    Compute 1 HSV feature of a cell. Return a row vector of size `n_orientations`
    """
    #hsv_image = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
    hue, sat, val = hsv_image[:,:,0], hsv_image[:,:,1], hsv_image[:,:,2]
    #return np.concatenate((np.ndarray.flatten(hue),np.ndarray.flatten(sat),np.ndarray.flatten(val)))
    return np.ndarray.flatten(hue)


def compute_hsv_features(image: np.ndarray, hsv_image,
                             n_orientations: int = 9, pixels_per_cell: (int, int) = (8, 8),
                             cells_per_block: (int, int) = (1, 1)) -> np.ndarray:
    """
    Compute HOG features of an image. Return a row vector
    """
    gx, gy = compute_gradient(image)
    sy, sx = gx.shape
    cx, cy = pixels_per_cell
    bx, by = cells_per_block

    magnitudes = np.hypot(gx, gy)  # = np.sqrt(gx**2 + gy**2)
    orientations = np.rad2deg(np.arctan2(gy, gx)) % 180

    n_cellsx = int(sx / cx)  # Number of cells in x axis
    n_cellsy = int(sy / cy)  # Number of cells in y axis
    n_blocksx = int(n_cellsx - bx) + 1
    n_blocksy = int(n_cellsy - by) + 1

    # hsv_cells = np.zeros((hsv_image.shape[0], hsv_image.shape[1]), np.uint8)
    hsv_cells = []
    
    prev_x = 0
    for it_x in range(n_cellsx):
        prev_y = 0
        for it_y in range(n_cellsy):
            hsv_array = compute_hsv_cell(hsv_image[prev_y:prev_y + cy, prev_x:prev_x + cx])
            hsv_array = np.reshape(hsv_array, -1)
            hsv_cells = np.append(hsv_cells, hsv_array)

            prev_y += cy
        prev_x += cx
       
    return hsv_cells


# TRAIN DATA FEATURES EXTRACTION WITH ORB
DETERMINE_CLASS = [int(0), int(1)]  # 0 for cracks and 1 for Spalls
training_data = np.array([])
vector_data = np.array([])
training_data_labels = np.array([])
class_data = np.array([])

# loop for each class folder
for classes in range(len(DETERMINE_CLASS)):
    files_path = '/home/liege/PycharmProjects/SVM/'+str(classes)

    # Number of images to be processed
    list = os.listdir(files_path)
    number_files = len(list)

    category = DETERMINE_CLASS[classes]

    # So the CSV feature line number is the same as the image name (also a number)
    for key in np.arange(0, number_files, 1):
        # Read image
        filename = str(key)
        image = cv2.imread(files_path + '/' + filename + '.jpg')
        #print(str(classes)+filename)
        image = cv2.resize(image, (800, 800))
        image1 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        #image = color.rgb2gray(image)
        hsv_image = cv2.cvtColor(image1, cv2.COLOR_RGB2HSV)
        

        # Process image
        vector_data = np.array([]) #hog_features,
        hsv_features = compute_hsv_features(
            hsv_image, hsv_image, n_orientations=9,
            pixels_per_cell=(8, 8),
            cells_per_block=(1, 1))
        #vector_data = np.append(vector_data, np.append(hog_features, hsv_features))
        vector_data = hsv_features
        vector_data = vector_data.reshape(1, vector_data.shape[0])

        # We need to concatenate on the full list of features extracted from each image
        if len(training_data) == 0:
            training_data = np.append(training_data, vector_data)
            training_data = training_data.reshape(vector_data.shape)
            # training_data_labels = np.append(training_data_labels,np.append(vector_data,category))
            class_data = np.append(class_data, category)
        else:
            training_data = np.concatenate((training_data, vector_data), axis=0)
            class_data = np.append(class_data, category)
            # training_data_labels = np.append(training_data_labels,np.append(vector_data,category))

X = training_data
y = class_data

#Apply PCA to reduce features
pca = PCA(n_components=4)
Xreduced = pca.fit_transform(X)

#SAVE FEATURES AND CLASSES TO AN CSV FILE
df = pd.DataFrame(Xreduced)
df.to_csv('X_HSV.csv', index=False)

df1 = pd.DataFrame(y)
df1.to_csv('y_HSV.csv', index=False)
